# NLTK - Natural Language Processing

import nltk


from nltk import sent_tokenize,word_tokenize

import nltk
#TOkenize - Spliting the paragraps into sentence , Spliting sentance into word
#Two type of Tokenize [Word,Sentance]

""""    #Lexican & Corporas
Corporas - Body of the Text Ex: "Hello World, How are you"
Lexican - Words and their meaning
Lexican can be simple english or Jorgan "Words" (Dictionary Words)"""

# From Tokenize, Sentance tokenize

se_to = ["Hello World", "It's good to see Thanks for coming"]

from nltk.tokenize import sent_tokenize

sent_tokenize(se_to)

# From Tokenize, Word Tokenize

wr_to = ['Hi Mr.Jagatheesh How are you I am waiting for you']

from nltk.tokenize import word_tokenize

dir (nltk.word_tokenize)


#print (nltk)

#molis = list(dir(nltk))
# Stop Words in NLTK

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

print (word_tokenize ('Hello jagatheesh, How are you'))
#stopword = set(stopwords.words('english'))

  #                   Tokenizer
  #                   /   |    \
  #   punkwordtokenizer   |    Treekwordtokenizer
  #                 regexptokenizer
  #                 /             \
  # wordpunktokenizer             whitespacetokenizer

# from nltk.tokenize import PunktWordTokenizer
# putok = PunktWordTokenizer()
# tokenizer.tokonize("How are you Buddy")
# ['How', 'are', 'you', 'buddy']

from nltk.tokenize import wordpunct_tokenize

wrputk1 = word_tokenize('How are you, How is work')

print (wrputk1)

# TOkenizer sentence using Regexp
from nltk.tokenize import regexp_tokenize

retok = regexp_tokenize("Can't is a construction","[\w]+")
print (retok)

retok1 = regexp_tokenize("My Employee No's 8107147, will it is my SAP, ID'S", "[\D]+")

print (retok1)

#White space tokenizer

whsp = "My Employee No's 8107147, will it is my SAP, ID'S"

wwhsp1 = "Krishna Kumar Barathi Dasan Murali Kannan Gopi Don"

tik1 = regexp_tokenize(wwhsp1,'\s', gaps = True)
print (tik1)

# New Project with Applied Text Mining
